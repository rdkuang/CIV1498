{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bphECiUa9zw"
   },
   "source": [
    "# Lab 5: Spam Detection\n",
    "\n",
    "**Deadline**: Monday, Mar 14, 5:00 PM\n",
    "\n",
    "**Late Penalty**: Any work that is submitted between 0 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.\n",
    "\n",
    "**TA**: Hossein Yousefi <hossein.yousefi@mail.utoronto.ca>\n",
    "\n",
    "In this assignment, we will build a recurrent neural network to classify a SMS text message\n",
    "as \"spam\" or \"not spam\". In the process, you will\n",
    "    \n",
    "1. Clean and process text data for machine learning.\n",
    "2. Understand and implement a character-level recurrent neural network.\n",
    "3. Use torchtext to build recurrent neural network models.\n",
    "4. Understand batching for a recurrent neural network, and use torchtext to implement RNN batching.\n",
    "\n",
    "### What to submit\n",
    "\n",
    "Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information (.html files are also acceptable).\n",
    "\n",
    "Do not submit any other files produced by your code.\n",
    "\n",
    "Include a link to your colab file in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWiUqJJTa9z6"
   },
   "source": [
    "## Colab Link\n",
    "\n",
    "Include a link to your Colab file here. If you would like the TA to look at your\n",
    "Colab file in case your solutions are cut off, **please make sure that your Colab\n",
    "file is publicly accessible at the time of submission**.\n",
    "\n",
    "Colab Link: https://drive.google.com/file/d/1Hsmb43lOXLCcggFP3eqeAYP0fPVE4yMZ/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HgfNOUaPa9z8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1647187013733,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "425Or-rW-43e",
    "outputId": "e541d4d0-7a94-4c1d-afc6-43ee2b6be397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16148,
     "status": "ok",
     "timestamp": 1647187029878,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "Tc7Ozku2_ke2",
    "outputId": "8a056ce4-87ba-4694-e1fa-4296ccc9ae58"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaLEIRa1_JNI"
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = \"/content/drive/MyDrive/Documents/Uni/School/FifthYear/APS360/lab5\"\n",
    "os.chdir(WORKING_DIR)\n",
    "DATASET_PATH = \"SMSSpamCollection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0jLI9LBa90C"
   },
   "source": [
    "## Part 1. Data Cleaning [15 pt]\n",
    "\n",
    "We will be using the \"SMS Spam Collection Data Set\" available at http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "\n",
    "There is a link to download the \"Data Folder\" at the very top of the webpage. Download the zip file, unzip it, and upload the file `SMSSpamCollection` to Colab.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1647103116082,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 300
    },
    "id": "MvbS4n2iSw2R",
    "outputId": "ec6955af-ee50-441f-ce54-ffa11694c1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-12 16:38:35--  http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 203415 (199K) [application/x-httpd-php]\n",
      "Saving to: ‘smsspamcollection.zip’\n",
      "\n",
      "smsspamcollection.z 100%[===================>] 198.65K   903KB/s    in 0.2s    \n",
      "\n",
      "2022-03-12 16:38:35 (903 KB/s) - ‘smsspamcollection.zip’ saved [203415/203415]\n",
      "\n",
      "Archive:  smsspamcollection.zip\n",
      "  inflating: SMSSpamCollection       \n",
      "  inflating: readme                  \n"
     ]
    }
   ],
   "source": [
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSuF7C_Ga90E"
   },
   "source": [
    "### Part (a) [2 pt]\n",
    "\n",
    "Open up the file in Python, and print out one example of a spam SMS, and one example of a non-spam SMS.\n",
    "\n",
    "What is the label value for a spam message, and what is the label value for a non-spam message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1647187032281,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "I_IfXHeTa90F",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a052c2ea-0f6e-47f4-85d2-d97c4536f444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "for line in open(DATASET_PATH):\n",
    "    category = line.split()[0]\n",
    "    if category not in seen:\n",
    "      print(line)\n",
    "      seen.add(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgKykl10UBzX"
   },
   "source": [
    "| Spam Message | Non-Spam Message |\n",
    "| --- | --- |\n",
    "| spam | ham |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AukA6vMVa90d"
   },
   "source": [
    "### Part (b) [1 pt]\n",
    "\n",
    "How many spam messages are there in the data set?\n",
    "How many non-spam messages are there in the data set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1647103138062,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 300
    },
    "id": "LgsqyemVa90e",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d8065ad8-99e6-4110-b77f-1adb2ea5e41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam messages = 747\n",
      "Number of non-spam messages = 4827\n"
     ]
    }
   ],
   "source": [
    "spam = 0\n",
    "ham = 0\n",
    "for line in open(DATASET_PATH):\n",
    "    category = line.split()[0]\n",
    "    if category == \"spam\":\n",
    "      spam += 1\n",
    "    elif category == \"ham\":\n",
    "      ham += 1\n",
    "    else:\n",
    "      raise\n",
    "\n",
    "print(\"Number of spam messages =\", spam)\n",
    "print(\"Number of non-spam messages =\", ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1WXxVt6a90h"
   },
   "source": [
    "### Part (c) [4 pt]\n",
    "\n",
    "We will be using the package `torchtext` to load, process, and batch the data.\n",
    "A tutorial to torchtext is available below. This tutorial uses the same\n",
    "Sentiment140 data set that we explored during lecture.\n",
    "\n",
    "https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8\n",
    "\n",
    "Unlike what we did during lecture, we will be building a **character level RNN**.\n",
    "That is, we will treat each **character** as a token in our sequence,\n",
    "rather than each **word**.\n",
    "\n",
    "Identify two advantage and two disadvantage of modelling SMS text\n",
    "messages as a sequence of characters rather than a sequence of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvDDH3WuYMfe"
   },
   "source": [
    "---\n",
    "**Advantages**\n",
    "1. Misspelled words or words that is not in the `Sentiment140` dataset will not be treated as a special `unknown` token; instead, they will be treated like other characters and be fed into the RNN. \n",
    "2. There is a small number of characters, making it easier to use one-hot encoding on all of the characters without the size of the encoding being too large. \n",
    "\n",
    "\n",
    "**Disadvantages**\n",
    "1. It is likely more computationally expensive than the word-level counterpart because it requires deeper networks to model long-term dependencies. \n",
    "2. It is likely to have lower accuracy than the word-level counterpart, since the grouping of each individual word is left for the network to learn, instead of directly given. Characters do not convey the meanings that are represented by words. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie_D0bv9a90k"
   },
   "source": [
    "### Part (d) [1 pt]\n",
    "\n",
    "We will be loading our data set using `torchtext.data.TabularDataset`. The\n",
    "constructor will read directly from the `SMSSpamCollection` file. \n",
    "\n",
    "For the data file to be read successfuly, we\n",
    "need to specify the **fields** (columns) in the file. \n",
    "In our case, the dataset has two fields: \n",
    "\n",
    "- a text field containing the sms messages,\n",
    "- a label field which will be converted into a binary label.\n",
    "\n",
    "Split the dataset into `train`, `valid`, and `test`. Use a 60-20-20 split.\n",
    "You may find this torchtext API page helpful:\n",
    "https://torchtext.readthedocs.io/en/latest/data.html#dataset\n",
    "\n",
    "Hint: There is a `Dataset` method that can perform the random split for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1647187041059,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "P_Y6Puz9a90l",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ddcfd041-f277-4c83-d9e5-fb508e13848f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.data' has no attribute 'Field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ca8cb82419ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m text_field = torchtext.data.Field(sequential=True,      # text sequence\n\u001b[0m\u001b[1;32m      5\u001b[0m                                         \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# because are building a character-RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                         \u001b[0minclude_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# to track the length of sequences, for batching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Field'"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import random\n",
    "\n",
    "text_field = torchtext.data.Field(sequential=True,      # text sequence\n",
    "                                        tokenize=lambda x: x, # because are building a character-RNN\n",
    "                                        include_lengths=True, # to track the length of sequences, for batching\n",
    "                                        batch_first=True,\n",
    "                                        use_vocab=True)       # to turn each character into an integer index\n",
    "label_field = torchtext.data.Field(sequential=False,    # not a sequence\n",
    "                                        use_vocab=False,     # don't need to track vocabulary\n",
    "                                        is_target=True,      \n",
    "                                        batch_first=True,\n",
    "                                        preprocessing=lambda x: int(x == 'spam')) # convert text to 0 and 1\n",
    "\n",
    "fields = [('label', label_field), ('email', text_field)]\n",
    "dataset = torchtext.legacy.data.TabularDataset(\"/Users/dakuang/Downloads/Project_1/test.csv\", # name of the file\n",
    "                                              \"csv\",               # fields are separated by a tab\n",
    "                                              fields)\n",
    "\n",
    "\n",
    "# print(dataset[0].sms)\n",
    "# print(dataset[0].label)\n",
    "\n",
    "random.seed(1000)\n",
    "\n",
    "train, valid_test  = dataset.split(split_ratio=0.6, random_state= random.getstate())\n",
    "valid, test = valid_test.split(split_ratio=0.5, random_state= random.getstate())\n",
    "print(\"train size:\", len(train))\n",
    "print(\"val size:\", len(valid))\n",
    "print(\"test size:\", len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6nP0Ks_a90o"
   },
   "source": [
    "### Part (e) [2 pt]\n",
    "\n",
    "You saw in part (b) that there are many more non-spam messages than spam messages.\n",
    "This **imbalance** in our training data will be problematic for training.\n",
    "We can fix this disparity by duplicating spam messages in the training set,\n",
    "so that the training set is roughly **balanced**.\n",
    "\n",
    "Explain why having a balanced training set is helpful for training our neural network.\n",
    "\n",
    "Note: if you are not sure, try removing the below code and train your mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "FWvx9_rka90p",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# save the original training examples\n",
    "old_train_examples = train.examples\n",
    "# get all the spam messages in `train`\n",
    "train_spam = []\n",
    "for item in train.examples:\n",
    "    if item.label == 1:\n",
    "        train_spam.append(item)\n",
    "# duplicate each spam message 6 more times\n",
    "train.examples = old_train_examples + train_spam * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIwmPXfTDrO7"
   },
   "source": [
    "---\n",
    "If the training set is imbalanced, then the network would be more likely to predict an input to be the one that it has seen more during training; in this case, there are more non-spam messages than spam messages, so the network is more likely to predict non-spam given a message. If we make the dataset roughly balanced, then the network won't have this inherent bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7eUmBEva90r"
   },
   "source": [
    "### Part (f) [1 pt]\n",
    "\n",
    "We need to build the vocabulary on the training data by running the below code.\n",
    "This finds all the possible character tokens in the training set.\n",
    "\n",
    "Explain what the variables `text_field.vocab.stoi` and `text_field.vocab.itos` represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1647187048066,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "8CQM8flKa90s",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fc5ff333-9505-4a11-c12b-c1f24259fa5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7ff19d6c68d0>>, {'<unk>': 0, '<pad>': 1, ' ': 2, 'e': 3, 'o': 4, 't': 5, 'a': 6, 'n': 7, 'r': 8, 'i': 9, 's': 10, 'l': 11, 'u': 12, '0': 13, 'h': 14, 'd': 15, '.': 16, 'c': 17, 'm': 18, 'y': 19, 'w': 20, 'p': 21, 'g': 22, '1': 23, 'f': 24, '2': 25, 'b': 26, '8': 27, 'T': 28, 'k': 29, 'E': 30, 'v': 31, '5': 32, 'S': 33, 'C': 34, 'O': 35, 'I': 36, '7': 37, '4': 38, 'N': 39, 'x': 40, 'A': 41, '3': 42, '6': 43, 'R': 44, '!': 45, ',': 46, '9': 47, 'P': 48, 'M': 49, 'U': 50, 'W': 51, 'L': 52, 'H': 53, 'D': 54, 'B': 55, 'Y': 56, '/': 57, 'F': 58, 'G': 59, \"'\": 60, '?': 61, '£': 62, '-': 63, '&': 64, ':': 65, 'X': 66, 'z': 67, 'V': 68, 'K': 69, 'j': 70, '*': 71, 'J': 72, ';': 73, ')': 74, '+': 75, 'Q': 76, '\"': 77, '(': 78, 'q': 79, '#': 80, '@': 81, '=': 82, 'Z': 83, '>': 84, 'ü': 85, 'Ü': 86, '<': 87, '_': 88, '$': 89, '\\x92': 90, '‘': 91, '[': 92, ']': 93, '¡': 94, '%': 95, '|': 96, '…': 97, '’': 98, '\\x93': 99, 'ú': 100, '“': 101, '–': 102, '\\x96': 103, 'é': 104, '\\t': 105, '\\n': 106, '\\\\': 107, '\\x94': 108, '\\x91': 109, '»': 110, 'É': 111, 'è': 112})\n",
      "['<unk>', '<pad>', ' ', 'e', 'o', 't', 'a', 'n', 'r', 'i', 's', 'l', 'u', '0', 'h', 'd', '.', 'c', 'm', 'y', 'w', 'p', 'g', '1', 'f', '2', 'b', '8', 'T', 'k', 'E', 'v', '5', 'S', 'C', 'O', 'I', '7', '4', 'N', 'x', 'A', '3', '6', 'R', '!', ',', '9', 'P', 'M', 'U', 'W', 'L', 'H', 'D', 'B', 'Y', '/', 'F', 'G', \"'\", '?', '£', '-', '&', ':', 'X', 'z', 'V', 'K', 'j', '*', 'J', ';', ')', '+', 'Q', '\"', '(', 'q', '#', '@', '=', 'Z', '>', 'ü', 'Ü', '<', '_', '$', '\\x92', '‘', '[', ']', '¡', '%', '|', '…', '’', '\\x93', 'ú', '“', '–', '\\x96', 'é', '\\t', '\\n', '\\\\', '\\x94', '\\x91', '»', 'É', 'è']\n"
     ]
    }
   ],
   "source": [
    "text_field.build_vocab(train)\n",
    "print(text_field.vocab.stoi)\n",
    "print(text_field.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1UVX764GnBm"
   },
   "source": [
    "---\n",
    "`text_field.vocab.stoi` provides a dictionary mapping token\n",
    "haracters set to their corresponding numerical identifier.\n",
    "`text_field.vocab.itos` provides a list of token characters set indexed by their numerical identifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC8WVE8Ua90u"
   },
   "source": [
    "### Part (g) [2 pt]\n",
    "\n",
    "The tokens `<unk>` and `<pad>` were not in our SMS text messages.\n",
    "What do these two values represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFm3IQvkHZMx"
   },
   "source": [
    "---\n",
    "`<unk>` represents \"unknown token\" which is used when a given word is not in the vocabulary (Out-of-Vocabulary or OOV). \n",
    "\n",
    "`<pad>` represents \"padding\" which is used to pad short sentences to ensure equial lengh input to the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff5CNk7Qa90y"
   },
   "source": [
    "### Part (h) [2 pt]\n",
    "\n",
    "Since text sequences are of variable length, `torchtext` provides a `BucketIterator` data loader,\n",
    "which batches similar length sequences together. The iterator also provides functionalities to\n",
    "pad sequences automatically.\n",
    "\n",
    "Take a look at 10 batches in `train_iter`. What is the maximum length of the\n",
    "input sequence in each batch? How many `<pad>` tokens are used in each of the 10\n",
    "batches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "V8N8qLWOa90y",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_iter = torchtext.legacy.data.BucketIterator(train,\n",
    "                                           batch_size=32,\n",
    "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
    "                                           sort_within_batch=True,        # sort within each batch\n",
    "                                           repeat=False)                  # repeat the iterator for many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1647103163459,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 300
    },
    "id": "Qwz-rOaha902",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c258415e-d11b-46a9-f987-5cb4a4dc3b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 1 --------------------\n",
      "Maximum length of input sequence: 32\n",
      "Number of <pad> tokens: 17\n",
      "-------------------- 2 --------------------\n",
      "Maximum length of input sequence: 107\n",
      "Number of <pad> tokens: 28\n",
      "-------------------- 3 --------------------\n",
      "Maximum length of input sequence: 150\n",
      "Number of <pad> tokens: 11\n",
      "-------------------- 4 --------------------\n",
      "Maximum length of input sequence: 65\n",
      "Number of <pad> tokens: 47\n",
      "-------------------- 5 --------------------\n",
      "Maximum length of input sequence: 134\n",
      "Number of <pad> tokens: 30\n",
      "-------------------- 6 --------------------\n",
      "Maximum length of input sequence: 148\n",
      "Number of <pad> tokens: 17\n",
      "-------------------- 7 --------------------\n",
      "Maximum length of input sequence: 158\n",
      "Number of <pad> tokens: 0\n",
      "-------------------- 8 --------------------\n",
      "Maximum length of input sequence: 40\n",
      "Number of <pad> tokens: 39\n",
      "-------------------- 9 --------------------\n",
      "Maximum length of input sequence: 124\n",
      "Number of <pad> tokens: 55\n",
      "-------------------- 10 --------------------\n",
      "Maximum length of input sequence: 101\n",
      "Number of <pad> tokens: 23\n"
     ]
    }
   ],
   "source": [
    "train_iter_iterator = iter(train_iter)\n",
    "\n",
    "for i in range(10):\n",
    "  print(\"-\"*20 + f\" {i+1} \" + \"-\"*20)\n",
    "  batch = next(train_iter_iterator)\n",
    "  max_len = batch.sms[0].shape[1]\n",
    "  print(\"Maximum length of input sequence:\", max_len)\n",
    "  print(\"Number of <pad> tokens:\", sum(max_len - batch.sms[1]).item())\n",
    "  \n",
    "  # print(len(batch))\n",
    "  # print(batch.sms)\n",
    "  # print(batch.label)\n",
    "  # print(len(batch.sms))\n",
    "  # print(batch)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7HnqP6_a904"
   },
   "source": [
    "## Part 2. Model Building [8 pt]\n",
    "\n",
    "Build a recurrent neural network model, using an architecture of your choosing. \n",
    "Use the one-hot embedding of each character as input to your recurrent network.\n",
    "Use one or more fully-connected layers to make the prediction based on your\n",
    "recurrent network output.\n",
    "\n",
    "Instead of using the RNN output value for the final token, another often used\n",
    "strategy is to max-pool over the entire output array. That is, instead of calling\n",
    "something like:\n",
    "\n",
    "```\n",
    "out, _ = self.rnn(x)\n",
    "self.fc(out[:, -1, :])\n",
    "```\n",
    "\n",
    "where `self.rnn` is an `nn.RNN`, `nn.GRU`, or `nn.LSTM` module, and `self.fc` is a \n",
    "fully-connected \n",
    "layer, we use:\n",
    "\n",
    "```\n",
    "out, _ = self.rnn(x)\n",
    "self.fc(torch.max(out, dim=1)[0])\n",
    "```\n",
    "\n",
    "This works reasonably in practice. An even better alternative is to concatenate the\n",
    "max-pooling and average-pooling of the RNN outputs:\n",
    "\n",
    "```\n",
    "out, _ = self.rnn(x)\n",
    "out = torch.cat([torch.max(out, dim=1)[0], \n",
    "                 torch.mean(out, dim=1)], dim=1)\n",
    "self.fc(out)\n",
    "```\n",
    "\n",
    "We encourage you to try out all these options. The way you pool the RNN outputs\n",
    "is one of the \"hyperparameters\" that you can choose to tune later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1647097229502,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 300
    },
    "id": "jHl1p_Wwa905",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "266919e3-1f8f-41b2-b056-920919dfbfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# You might find this code helpful for obtaining\n",
    "# PyTorch one-hot vectors.\n",
    "\n",
    "ident = torch.eye(10)\n",
    "print(ident[0]) # one-hot vector\n",
    "print(ident[1]) # one-hot vector\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "print(ident[x]) # one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1647103258224,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 300
    },
    "id": "4LTQ7zFka909",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5f87bd90-5fc3-48cd-c77b-fea5f1b88312"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_field.vocab) # Size of one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E047fSd7t1zN"
   },
   "outputs": [],
   "source": [
    "class SpamNet(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ident = torch.eye(vocab_size)\n",
    "        self.name = \"SpamNet\"\n",
    "\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Look up the embedding\n",
    "        x = self.ident[x]\n",
    "        x = x.to(device)\n",
    "\n",
    "        # Set an initial hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = torch.cat([torch.max(out, dim=1)[0], \n",
    "                         torch.mean(out, dim=1)], dim=1)\n",
    "        # out = self.fc(out[:, -1, :])\n",
    "        # out = self.fc(torch.max(out, dim=1)[0])\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKIYPl_Ba90_"
   },
   "source": [
    "## Part 3. Training [16 pt]\n",
    "\n",
    "### Part (a) [4 pt]\n",
    "\n",
    "Complete the `get_accuracy` function, which will compute the\n",
    "accuracy (rate) of your model across a dataset (e.g. validation set).\n",
    "You may modify `torchtext.data.BucketIterator` to make your computation\n",
    "faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1647196080966,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "pvNfhGD6a91A",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, data):\n",
    "    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n",
    "    \n",
    "    Example usage:\n",
    "    \n",
    "    >>> model = MyRNN() # to be defined\n",
    "    >>> get_accuracy(model, valid) # the variable `valid` is from above\n",
    "    \"\"\"\n",
    "\n",
    "    data_iter = torchtext.legacy.data.BucketIterator(data,\n",
    "                                           batch_size=len(data),\n",
    "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
    "                                           sort_within_batch=True,        # sort within each batch\n",
    "                                           repeat=False)                  # repeat the iterator for many epochs\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for sms, label in data_iter:\n",
    "        sms, label = sms[0].to(device), label.to(device)\n",
    "        output = model(sms)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "        total += label.shape[0]\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-bt56FW8bOj"
   },
   "outputs": [],
   "source": [
    "def evaluate(net, loader, criterion):\n",
    "    \"\"\" Evaluate the network on the validation set.\n",
    "\n",
    "     Args:\n",
    "         net: PyTorch neural network object\n",
    "         loader: PyTorch data loader for the validation set\n",
    "         criterion: The loss function\n",
    "     Returns:\n",
    "         acc: A scalar for the avg classification accuracy over the validation set\n",
    "         loss: A scalar for the average loss function over the validation set\n",
    "     \"\"\"\n",
    "     \n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_epoch = 0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = inputs[0].to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Get the index of the max log-probability\n",
    "        pred = outputs.max(1, keepdim=True)[1] \n",
    "\n",
    "        # Check for correctness\n",
    "        corr = pred.eq(labels.view_as(pred))\n",
    "\n",
    "        total_acc += int(corr.sum().item())\n",
    "        total_loss += loss.item()\n",
    "        total_epoch += len(labels)\n",
    "\n",
    "    acc = float(total_acc) / total_epoch\n",
    "    loss = float(total_loss) / (i + 1)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlxlcAC1a91C"
   },
   "source": [
    "### Part (b) [4 pt]\n",
    "\n",
    "Train your model. Plot the training curve of your final model. \n",
    "Your training curve should have the training/validation loss and\n",
    "accuracy plotted periodically.\n",
    "\n",
    "Note: Not all of your batches will have the same batch size.\n",
    "In particular, if your training set does not divide evenly by\n",
    "your batch size, there will be a batch that is smaller than\n",
    "the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0u4aRZJS-Aqu"
   },
   "outputs": [],
   "source": [
    "def get_model_name(name, batch_size, learning_rate, epoch, path_prefix=\"\"):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    if path_prefix != \"\" and not os.path.exists(path_prefix):\n",
    "        os.makedirs(path_prefix)\n",
    "\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    \n",
    "    return os.path.join(path_prefix, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1Y3yHJN-CFm"
   },
   "outputs": [],
   "source": [
    "def plot_training_curve(path):\n",
    "    \"\"\" Plots the training curve for a model run, given the csv files\n",
    "    containing the train/validation accuracy/loss.\n",
    "\n",
    "    Args:\n",
    "        path: The base path of the csv files produced during training\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
    "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    plt.title(\"Train vs Validation Accuracy\")\n",
    "    n = len(train_acc) # number of epochs\n",
    "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CVtf7CJCa91D",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_net(net, \n",
    "              train_set, val_set,\n",
    "              path_prefix=\"\", \n",
    "              batch_size=64, \n",
    "              learning_rate=0.01, \n",
    "              num_epochs=30,\n",
    "              num_workers=1,\n",
    "              sanity_check=False,\n",
    "              device=None,\n",
    "              **kwargs):\n",
    "\n",
    "    if not device:\n",
    "      device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "    train_iter = torchtext.legacy.data.BucketIterator(train_set,\n",
    "                                                      device=device,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      sort_key=lambda x: len(x.sms), # to minimize padding\n",
    "                                                      sort_within_batch=True,        # sort within each batch\n",
    "                                                      repeat=False)                  # repeat the iterator for many epochs\n",
    "    val_iter = torchtext.legacy.data.BucketIterator(val_set,\n",
    "                                                      device=device,\n",
    "                                                      batch_size=len(val_set),\n",
    "                                                      sort_key=lambda x: len(x.sms), # to minimize padding\n",
    "                                                      sort_within_batch=True,        # sort within each batch\n",
    "                                                      repeat=False)                  # repeat the iterator for many epochs\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer=optim.Adam(net.parameters(),lr=learning_rate)\n",
    "\n",
    "    ########################################################################\n",
    "    # Set up some numpy arrays to store the training/test loss/accuracy\n",
    "    train_acc = np.zeros(num_epochs)\n",
    "    train_loss = np.zeros(num_epochs)\n",
    "    val_acc = np.zeros(num_epochs)\n",
    "    val_loss = np.zeros(num_epochs)\n",
    "    ########################################################################\n",
    "    # Train the network\n",
    "    # Loop over the data iterator and sample a new batch of training data\n",
    "    # Get the output from the network, and optimize our loss function.\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        total_train_loss = 0.0\n",
    "        total_train_acc = 0.0\n",
    "        total_epoch = 0\n",
    "        for i, data in enumerate(train_iter, 0):\n",
    "            # Get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Move the inputs and labels to gpu if possible\n",
    "            inputs, labels = inputs[0].to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass, backward pass, and optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print(f\"inputs: {inputs.size()}, , labels: {labels.size()}, outputs: {outputs.size()}\")\n",
    "            # print(\"---\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate the statistics\n",
    "            # Get the index of the max log-probability\n",
    "            pred = outputs.max(1, keepdim=True)[1] \n",
    "\n",
    "            # Check for correctness\n",
    "            corr = pred.eq(labels.view_as(pred))\n",
    "\n",
    "            total_train_acc += int(corr.sum().item())\n",
    "            total_train_loss += loss.item()\n",
    "            total_epoch += len(labels)\n",
    "        \n",
    "        train_acc[epoch] = float(total_train_acc) / total_epoch\n",
    "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
    "        \n",
    "        val_acc[epoch], val_loss[epoch] = evaluate(net, val_iter, criterion)\n",
    "\n",
    "        print((\"Epoch {}: Train acc: {}, Train loss: {} |\"+\n",
    "               \"Validation acc: {}, Validation loss: {}\").format(\n",
    "                   epoch + 1,\n",
    "                   train_acc[epoch],\n",
    "                   train_loss[epoch],\n",
    "                   val_acc[epoch],\n",
    "                   val_loss[epoch]))\n",
    "        \n",
    "        # Save the current model (checkpoint) to a file\n",
    "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch, path_prefix=path_prefix)\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "    \n",
    "    print('Finished Training')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "    # Write the train/test loss/acc into CSV file for plotting later\n",
    "    epochs = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
    "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
    "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
    "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50798,
     "status": "ok",
     "timestamp": 1647187281990,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "EkpGZE-h-jIl",
    "outputId": "e50b2e9b-ff04-409b-9e01-cd3ef5ce17ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train acc: 0.8209926769731489, Train loss: 0.3883919476439761 |Validation acc: 0.9658886894075404, Validation loss: 0.16700361669063568\n",
      "Epoch 2: Train acc: 0.9539462978030919, Train loss: 0.13994159388544106 |Validation acc: 0.9452423698384201, Validation loss: 0.1848687380552292\n",
      "Epoch 3: Train acc: 0.9656631407648495, Train loss: 0.1091431203959365 |Validation acc: 0.9802513464991023, Validation loss: 0.06493406742811203\n",
      "Epoch 4: Train acc: 0.9718470301057771, Train loss: 0.08848254433640042 |Validation acc: 0.9847396768402155, Validation loss: 0.05657554790377617\n",
      "Epoch 5: Train acc: 0.9707078925956062, Train loss: 0.07153417060026233 |Validation acc: 0.9784560143626571, Validation loss: 0.07631871104240417\n",
      "Epoch 6: Train acc: 0.9814483319772173, Train loss: 0.056828004498049194 |Validation acc: 0.9856373429084381, Validation loss: 0.04881724715232849\n",
      "Epoch 7: Train acc: 0.9887713588283157, Train loss: 0.03705464956746316 |Validation acc: 0.9856373429084381, Validation loss: 0.04732263460755348\n",
      "Epoch 8: Train acc: 0.9848657445077299, Train loss: 0.038676561921330684 |Validation acc: 0.9847396768402155, Validation loss: 0.045570991933345795\n",
      "Epoch 9: Train acc: 0.9923515052888527, Train loss: 0.02913812464531366 |Validation acc: 0.9784560143626571, Validation loss: 0.06056573614478111\n",
      "Epoch 10: Train acc: 0.9977217249796583, Train loss: 0.012697369358176606 |Validation acc: 0.9865350089766607, Validation loss: 0.05197335407137871\n",
      "Epoch 11: Train acc: 0.9949552481692433, Train loss: 0.01645858628811662 |Validation acc: 0.9892280071813285, Validation loss: 0.04406668245792389\n",
      "Epoch 12: Train acc: 0.9990235964198535, Train loss: 0.006788548515466285 |Validation acc: 0.9874326750448833, Validation loss: 0.04877321049571037\n",
      "Epoch 13: Train acc: 0.9990235964198535, Train loss: 0.006037865421858253 |Validation acc: 0.9874326750448833, Validation loss: 0.056337058544158936\n",
      "Epoch 14: Train acc: 1.0, Train loss: 0.0038651365385972292 |Validation acc: 0.9892280071813285, Validation loss: 0.05682319030165672\n",
      "Epoch 15: Train acc: 1.0, Train loss: 0.0011858347301539384 |Validation acc: 0.9883303411131059, Validation loss: 0.053733501583337784\n",
      "Epoch 16: Train acc: 1.0, Train loss: 0.0008939786352874446 |Validation acc: 0.9883303411131059, Validation loss: 0.06687058508396149\n",
      "Epoch 17: Train acc: 1.0, Train loss: 0.0005208551973044761 |Validation acc: 0.9892280071813285, Validation loss: 0.06797274202108383\n",
      "Epoch 18: Train acc: 1.0, Train loss: 0.00039878085083968695 |Validation acc: 0.9883303411131059, Validation loss: 0.07168932259082794\n",
      "Epoch 19: Train acc: 1.0, Train loss: 0.00034917759597432674 |Validation acc: 0.9883303411131059, Validation loss: 0.06500767171382904\n",
      "Epoch 20: Train acc: 1.0, Train loss: 0.00023455871775219462 |Validation acc: 0.9874326750448833, Validation loss: 0.07263161242008209\n",
      "Epoch 21: Train acc: 1.0, Train loss: 0.00020445516148766526 |Validation acc: 0.9874326750448833, Validation loss: 0.07315902411937714\n",
      "Epoch 22: Train acc: 1.0, Train loss: 0.00013838073590624768 |Validation acc: 0.9874326750448833, Validation loss: 0.07569203525781631\n",
      "Epoch 23: Train acc: 1.0, Train loss: 0.00013561563905851364 |Validation acc: 0.9874326750448833, Validation loss: 0.07805470377206802\n",
      "Epoch 24: Train acc: 1.0, Train loss: 0.00012584297137130499 |Validation acc: 0.9874326750448833, Validation loss: 0.07634635269641876\n",
      "Epoch 25: Train acc: 1.0, Train loss: 8.547242609103818e-05 |Validation acc: 0.9865350089766607, Validation loss: 0.08049111068248749\n",
      "Finished Training\n",
      "Total time elapsed: 41.38 seconds\n"
     ]
    }
   ],
   "source": [
    "model = SpamNet(vocab_size=len(text_field.vocab), \n",
    "                hidden_size=len(text_field.vocab), \n",
    "                num_classes=2).to(device)\n",
    "training_params = {\n",
    "    \"net\": model,\n",
    "    \"train_set\": train,\n",
    "    \"val_set\": valid,\n",
    "    \"path_prefix\": \"default\",\n",
    "    \"network_name\": model.__class__.__name__,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 25,\n",
    "    \"num_workers\": 2,\n",
    "    \"device\": device\n",
    "\n",
    "}\n",
    "train_net(**training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1647187347270,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "JyaQwdEnItv1",
    "outputId": "fc46d60e-011c-48f2-956e-1ea46a5f99cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = get_model_name(training_params[\"network_name\"], \n",
    "                            batch_size=training_params[\"batch_size\"], \n",
    "                            learning_rate=training_params[\"learning_rate\"], \n",
    "                            epoch=training_params[\"num_epochs\"] - 1,\n",
    "                            path_prefix=training_params[\"path_prefix\"])\n",
    "\n",
    "plot_training_curve(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE3eRkDAa91F"
   },
   "source": [
    "### Part (c) [4 pt]\n",
    "\n",
    "Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\n",
    "You don't need to include your training curve for every model you trained.\n",
    "Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n",
    "and the reasoning behind the hyperparameter decisions you made.\n",
    "\n",
    "For this assignment, you should tune more than just your learning rate and epoch. \n",
    "Choose at least 2 hyperparameters that are unrelated to the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSAThjFsCIJU"
   },
   "source": [
    "---\n",
    "\n",
    "| Hyperparameter | \n",
    "| --- | \n",
    "| RNN output pooling method | \n",
    "| Number of hidden layers|\n",
    "| Learning rate|\n",
    "| Batch size|\n",
    "\n",
    "| No. | Pooling | No. Hidden | lr | bs | val. acc. | Reasoning |\n",
    "| --- | --- | --- | --- | --- | --- | --- | \n",
    "| 1 | Max Pooling | 0 | 1e-3 | 64 | 0.96 | Compare the difference between <br> max, average, and concat methods |\n",
    "| 2 | Final Token | 0 | 1e-3 | 64 | 0.91 | Compare the difference between <br> max, average, and concat methods |\n",
    "| 3 | Concat Max & Mean | 0 | 1e-3 | 64 | 0.99 | Compare the difference between <br> max, average, and concat methods. <br>The concat max & min method seems to<br> work the best. |\n",
    "| 4 | Concat Max & Mean | 0 | 1e-3 | 512 | 0.98 | Increase the batch size for faster training |\n",
    "| 5 | Concat Max & Mean | 0 | 1e-2 | 512 | 0.96 | Increase the learning rate to match the <br>larger batch size |\n",
    "| 6 | Concat Max & Mean | 1 | 1e-3 | 64 | 0.99 | Added a hidden layer to see if it can help the <br>network learn more abstract features. I had to <br>use leaky ReLU because with ReLU, the training <br>did not converge.  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1647190103999,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "n3Yw7gdjKAyB"
   },
   "outputs": [],
   "source": [
    "class SpamNet2(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ident = torch.eye(vocab_size)\n",
    "        self.name = \"SpamNet2\"\n",
    "\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Look up the embedding\n",
    "        x = self.ident[x]\n",
    "        x = x.to(device)\n",
    "\n",
    "        # Set an initial hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = torch.cat([torch.max(out, dim=1)[0], \n",
    "                         torch.mean(out, dim=1)], dim=1)\n",
    "        # out = self.fc(out[:, -1, :])\n",
    "        # out = self.fc(torch.max(out, dim=1)[0])\n",
    "        out = F.leaky_relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34696,
     "status": "ok",
     "timestamp": 1647190140237,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "18Qz5PJKH7A9",
    "outputId": "4cd28271-d3fa-47d4-a660-2ae2d11e3b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train acc: 0.5178193653376729, Train loss: 0.6936864880556913 |Validation acc: 0.11759425493716337, Validation loss: 0.7715349793434143\n",
      "Epoch 2: Train acc: 0.8022782750203418, Train loss: 0.38919939006649956 |Validation acc: 0.9748653500897666, Validation loss: 0.14515948295593262\n",
      "Epoch 3: Train acc: 0.934092758340114, Train loss: 0.19857449340394018 |Validation acc: 0.9622980251346499, Validation loss: 0.14915576577186584\n",
      "Epoch 4: Train acc: 0.9485760781122864, Train loss: 0.152131143794155 |Validation acc: 0.966786355475763, Validation loss: 0.10712765902280807\n",
      "Epoch 5: Train acc: 0.957526444263629, Train loss: 0.14364916523054397 |Validation acc: 0.9658886894075404, Validation loss: 0.10622607916593552\n",
      "Epoch 6: Train acc: 0.9609438567941416, Train loss: 0.11589746466194539 |Validation acc: 0.9802513464991023, Validation loss: 0.07288841903209686\n",
      "Epoch 7: Train acc: 0.9648494711147274, Train loss: 0.11011638224950616 |Validation acc: 0.9614003590664273, Validation loss: 0.12597256898880005\n",
      "Epoch 8: Train acc: 0.9685923515052889, Train loss: 0.09255414673117633 |Validation acc: 0.9793536804308797, Validation loss: 0.07934000343084335\n",
      "Epoch 9: Train acc: 0.9783563873067534, Train loss: 0.07066563075917207 |Validation acc: 0.9820466786355476, Validation loss: 0.06032967567443848\n",
      "Epoch 10: Train acc: 0.9775427176566314, Train loss: 0.061593016107883494 |Validation acc: 0.9793536804308797, Validation loss: 0.07105778902769089\n",
      "Epoch 11: Train acc: 0.9830756712774613, Train loss: 0.048099172158771644 |Validation acc: 0.9838420107719928, Validation loss: 0.051732733845710754\n",
      "Epoch 12: Train acc: 0.9856794141578519, Train loss: 0.04749201881920093 |Validation acc: 0.9829443447037702, Validation loss: 0.059307243674993515\n",
      "Epoch 13: Train acc: 0.9886086248982913, Train loss: 0.033927152939644864 |Validation acc: 0.9865350089766607, Validation loss: 0.06004219129681587\n",
      "Epoch 14: Train acc: 0.9949552481692433, Train loss: 0.0182221293336587 |Validation acc: 0.9829443447037702, Validation loss: 0.06739446520805359\n",
      "Epoch 15: Train acc: 0.9986981285598047, Train loss: 0.011359240421389239 |Validation acc: 0.9874326750448833, Validation loss: 0.05277380719780922\n",
      "Epoch 16: Train acc: 0.9995117982099267, Train loss: 0.007309554619852636 |Validation acc: 0.9874326750448833, Validation loss: 0.05440367013216019\n",
      "Epoch 17: Train acc: 0.9998372660699756, Train loss: 0.0037822621672284626 |Validation acc: 0.9883303411131059, Validation loss: 0.055419351905584335\n",
      "Epoch 18: Train acc: 1.0, Train loss: 0.002565173346719695 |Validation acc: 0.9847396768402155, Validation loss: 0.057434484362602234\n",
      "Epoch 19: Train acc: 0.9998372660699756, Train loss: 0.0036983385185315634 |Validation acc: 0.9865350089766607, Validation loss: 0.06250115483999252\n",
      "Epoch 20: Train acc: 1.0, Train loss: 0.0011065416661368386 |Validation acc: 0.9874326750448833, Validation loss: 0.06159143149852753\n",
      "Epoch 21: Train acc: 1.0, Train loss: 0.0009493234662381697 |Validation acc: 0.9883303411131059, Validation loss: 0.07390043884515762\n",
      "Epoch 22: Train acc: 1.0, Train loss: 0.0007732577005955726 |Validation acc: 0.9883303411131059, Validation loss: 0.06758002191781998\n",
      "Epoch 23: Train acc: 1.0, Train loss: 0.0005497282994810186 |Validation acc: 0.9883303411131059, Validation loss: 0.06864459067583084\n",
      "Epoch 24: Train acc: 1.0, Train loss: 0.0004378385543419689 |Validation acc: 0.9892280071813285, Validation loss: 0.07371442764997482\n",
      "Epoch 25: Train acc: 1.0, Train loss: 0.00032710692282317093 |Validation acc: 0.9892280071813285, Validation loss: 0.07574538141489029\n",
      "Finished Training\n",
      "Total time elapsed: 34.52 seconds\n"
     ]
    }
   ],
   "source": [
    "model = SpamNet2(vocab_size=len(text_field.vocab), \n",
    "                hidden_size=len(text_field.vocab), \n",
    "                num_classes=2).to(device)\n",
    "training_params = {\n",
    "    \"net\": model,\n",
    "    \"train_set\": train,\n",
    "    \"val_set\": valid,\n",
    "    \"path_prefix\": \"spamnet2_default\",\n",
    "    \"network_name\": model.__class__.__name__,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 25,\n",
    "    \"num_workers\": 2,\n",
    "    \"device\": device\n",
    "\n",
    "}\n",
    "train_net(**training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7DY56rKa91I"
   },
   "source": [
    "### Part (d) [2 pt]\n",
    "\n",
    "Before we deploy a machine learning model, we usually want to have a better understanding\n",
    "of how our model performs beyond its validation accuracy. An important metric to track is\n",
    "*how well our model performs in certain subsets of the data*.\n",
    "\n",
    "In particular, what is the model's error rate amongst data with negative labels?\n",
    "This is called the **false positive rate**.\n",
    "\n",
    "What about the model's error rate amongst data with positive labels?\n",
    "This is called the **false negative rate**.\n",
    "\n",
    "Report your final model's false positive and false negative rate across the\n",
    "validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1647194050018,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "LG8khTLFaIqP"
   },
   "outputs": [],
   "source": [
    "def confusion(dataset):\n",
    "  # Create a Dataset of only spam dataset examples\n",
    "  spam = torchtext.legacy.data.Dataset(\n",
    "      [e for e in dataset.examples if e.label == 1],\n",
    "      dataset.fields)\n",
    "  # Create a Dataset of only non-spam dataset examples\n",
    "  nospam = torchtext.legacy.data.Dataset(\n",
    "      [e for e in dataset.examples if e.label == 0],\n",
    "      dataset.fields)\n",
    "\n",
    "  tn = get_accuracy(model, nospam)\n",
    "  fp = 1 - tn\n",
    "  tp = get_accuracy(model, spam)\n",
    "  fn = 1 - tp\n",
    "\n",
    "  return tn, fp, tp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1647194054876,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "7ggbQSdba91J",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7cb6d0b0-f2f2-48ef-94bc-8c0033a10787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive:  0.10172939979654627 %\n",
      "False negative:  8.3969465648855 %\n"
     ]
    }
   ],
   "source": [
    "model = SpamNet2(vocab_size=len(text_field.vocab), \n",
    "                hidden_size=len(text_field.vocab), \n",
    "                num_classes=2).to(device)\n",
    "\n",
    "training_params = {\n",
    "    \"net\": model,\n",
    "    \"train_set\": train,\n",
    "    \"val_set\": valid,\n",
    "    \"path_prefix\": \"spamnet2_default\",\n",
    "    \"network_name\": model.__class__.__name__,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 25,\n",
    "    \"num_workers\": 2,\n",
    "    \"device\": device\n",
    "\n",
    "}\n",
    "\n",
    "model_path = get_model_name(training_params[\"network_name\"], \n",
    "                            batch_size=training_params[\"batch_size\"], \n",
    "                            learning_rate=training_params[\"learning_rate\"], \n",
    "                            epoch=25 - 1,\n",
    "                            path_prefix=training_params[\"path_prefix\"])\n",
    "state = torch.load(model_path)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "_, fp, _, fn = confusion(valid)\n",
    "\n",
    "print(\"False positive: \", fp * 100, \"%\")\n",
    "print(\"False negative: \", fn * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1iRteb3a91O"
   },
   "source": [
    "### Part (e) [2 pt]\n",
    "\n",
    "The impact of a false positive vs a false negative can be drastically different.\n",
    "If our spam detection algorithm was deployed on your phone, what is the impact\n",
    "of a false positive on the phone's user? What is the impact of a false negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6X4xvRHZTg5"
   },
   "source": [
    "* Impact of false positive: missed messages due to the algorithm misclassifying non-spam messages to spam. \n",
    "* Impact of false negative: receive spam messages because the algorithm classified it as non-spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gznefulsa91V"
   },
   "source": [
    "## Part 4. Evaluation [11 pt]\n",
    "\n",
    "### Part (a) [1 pt]\n",
    "\n",
    "Report the final test accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1647194695872,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "D5L5D-A1a91W",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "46a92907-147d-40cf-d09c-f4e0d9ef0b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115, 446])\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "Test accuracy:  97.9372197309417 %\n"
     ]
    }
   ],
   "source": [
    "model = SpamNet2(vocab_size=len(text_field.vocab), \n",
    "                hidden_size=len(text_field.vocab), \n",
    "                num_classes=2).to(device)\n",
    "\n",
    "training_params = {\n",
    "    \"net\": model,\n",
    "    \"train_set\": train,\n",
    "    \"val_set\": valid,\n",
    "    \"path_prefix\": \"spamnet2_default\",\n",
    "    \"network_name\": model.__class__.__name__,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 25,\n",
    "    \"num_workers\": 2,\n",
    "    \"device\": device\n",
    "\n",
    "}\n",
    "\n",
    "model_path = get_model_name(training_params[\"network_name\"], \n",
    "                            batch_size=training_params[\"batch_size\"], \n",
    "                            learning_rate=training_params[\"learning_rate\"], \n",
    "                            epoch=25 - 1,\n",
    "                            path_prefix=training_params[\"path_prefix\"])\n",
    "state = torch.load(model_path)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "test_acc = get_accuracy(model, test)\n",
    "print(\"Test accuracy: \", test_acc * 100, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hjmd8rca91Y"
   },
   "source": [
    "### Part (b) [3 pt]\n",
    "\n",
    "Report the false positive rate and false negative rate of your model across the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1647194103856,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "GFiAKztJa91Z",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f82cb99f-2c6b-48ef-af6a-fb1845562d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive:  0.5175983436852993 %\n",
      "False negative:  11.409395973154357 %\n"
     ]
    }
   ],
   "source": [
    "_, fp, _, fn = confusion(test)\n",
    "print(\"False positive: \", fp * 100, \"%\")\n",
    "print(\"False negative: \", fn * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jGHtQFpa91b"
   },
   "source": [
    "### Part (c) [3 pt]\n",
    "\n",
    "What is your model's prediction of the **probability** that\n",
    "the SMS message \"machine learning is sooo cool!\" is spam?\n",
    "\n",
    "Hint: To begin, use `text_field.vocab.stoi` to look up the index\n",
    "of each character in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1647194334023,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "CCcmxyCfbbb9",
    "outputId": "8d59ca52-ea43-4ac4-e751-bbaa1863eeaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.stoi[iter(\"hello\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1647194997065,
     "user": {
      "displayName": "Yifan Lu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3mO9arbKO8PsujoGig1HDIyODZyvAwxAln-XK2A=s64",
      "userId": "13144022923262331696"
     },
     "user_tz": 240
    },
    "id": "h_2nSJq8a91b",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2aab9b1c-bb9d-4a37-c2b7-7ffc6cd2c0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam probability: 0.19991581793874502 %\n"
     ]
    }
   ],
   "source": [
    "msg = \"machine learning is sooo cool!\"\n",
    "input = torch.LongTensor([text_field.vocab.stoi[s] for s in msg]).unsqueeze(0)\n",
    "input = input.to(device)\n",
    "\n",
    "out = model(input)\n",
    "m = nn.Softmax(dim=1)\n",
    "pred = m(out).cpu().detach().numpy()[0][1]\n",
    "\n",
    "print(\"Spam probability:\", pred * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QD1zgYJpa91f"
   },
   "source": [
    "### Part (d) [4 pt]\n",
    "\n",
    "Do you think detecting spam is an easy or difficult task?\n",
    "\n",
    "Since machine learning models are expensive to train and deploy, it is very\n",
    "important to compare our models against baseline models: a simple\n",
    "model that is easy to build and inexpensive to run that we can compare our\n",
    "recurrent neural network model against.\n",
    "\n",
    "Explain how you might build a simple baseline model. This baseline model\n",
    "can be a simple neural network (with very few weights), a hand-written algorithm,\n",
    "or any other strategy that is easy to build and test.\n",
    "\n",
    "**Do not actually build a baseline model. Instead, provide instructions on\n",
    "how to build it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-86qizAg_9i"
   },
   "source": [
    "---\n",
    "Spam detection is generally a difficult task. Because the tolerance of false positive is very low, as users never want to miss any messages. However, for applications that don't require a very low false positive rate, then the detection can be easy, since spam messages are usually associated with certain features such as keywords. \n",
    "\n",
    "A simple baseline model can be a fully connected neural network. Glove embeddings of each word can be used to tokenize the input, which is then concatenated and fed into a fully-connected network with non-linear activations. The output is a binary classification and we can use a Binary Cross Entropy loss function to train the network. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_5_Spam_Detection_Winter_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
